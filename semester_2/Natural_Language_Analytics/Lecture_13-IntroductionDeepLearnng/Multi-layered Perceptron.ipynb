{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Multi-layer Perceptron\n",
    "\n",
    "This notebook is an example of a multi-layer perceptron with Keras (https://keras.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/petasis/.local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using Theano backend.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "ERROR (theano.gpuarray): pygpu was configured but could not be imported or is too old (version 0.7 or higher required)\n",
      "NoneType: None\n"
     ]
    }
   ],
   "source": [
    "# Import some needed packages\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "We are going to load the tweets from SemEval 2018..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../Exercise_2-TwitterSentimentAnalysis/data/twitter-2013train-A.tsv', '../Exercise_2-TwitterSentimentAnalysis/data/twitter-2015train-A.tsv', '../Exercise_2-TwitterSentimentAnalysis/data/twitter-2016train-A.tsv']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "fpattern = '../Exercise_2-TwitterSentimentAnalysis/data/twitter-20*train-*.tsv'\n",
    "filenames = [filename for filename in sorted(glob.glob(fpattern))]\n",
    "print(filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16045 entries, 0 to 16044\n",
      "Data columns (total 3 columns):\n",
      "id       16045 non-null int64\n",
      "tag      16045 non-null object\n",
      "tweet    16045 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 376.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tag</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>264183816548130816</td>\n",
       "      <td>positive</td>\n",
       "      <td>Gas by my house hit $3.39!!!! I'm going to Cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>263405084770172928</td>\n",
       "      <td>negative</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262163168678248449</td>\n",
       "      <td>negative</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264249301910310912</td>\n",
       "      <td>negative</td>\n",
       "      <td>Iranian general says Israel's Iron Dome can't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>262682041215234048</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id       tag  \\\n",
       "0  264183816548130816  positive   \n",
       "1  263405084770172928  negative   \n",
       "2  262163168678248449  negative   \n",
       "3  264249301910310912  negative   \n",
       "4  262682041215234048   neutral   \n",
       "\n",
       "                                               tweet  \n",
       "0  Gas by my house hit $3.39!!!! I'm going to Cha...  \n",
       "1                                      Not Available  \n",
       "2                                      Not Available  \n",
       "3  Iranian general says Israel's Iron Dome can't ...  \n",
       "4                                      Not Available  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all files into a big data frame...\n",
    "column_names = ['id', 'tag', 'tweet']\n",
    "df = pd.concat([pd.read_csv(f, sep=\"\\t\", names=column_names) for f in filenames], ignore_index=True, sort=True)\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11918 entries, 0 to 16044\n",
      "Data columns (total 3 columns):\n",
      "id       11918 non-null int64\n",
      "tag      11918 non-null object\n",
      "tweet    11918 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 372.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tag</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>264183816548130816</td>\n",
       "      <td>positive</td>\n",
       "      <td>Gas by my house hit $3.39!!!! I'm going to Cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264249301910310912</td>\n",
       "      <td>negative</td>\n",
       "      <td>Iranian general says Israel's Iron Dome can't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>264105751826538497</td>\n",
       "      <td>positive</td>\n",
       "      <td>with J Davlar 11th. Main rivals are team Polan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>264094586689953794</td>\n",
       "      <td>negative</td>\n",
       "      <td>Talking about ACT's &amp;amp;&amp;amp; SAT's, deciding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>254941790757601280</td>\n",
       "      <td>negative</td>\n",
       "      <td>They may have a SuperBowl in Dallas, but Dalla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id       tag  \\\n",
       "0  264183816548130816  positive   \n",
       "3  264249301910310912  negative   \n",
       "6  264105751826538497  positive   \n",
       "7  264094586689953794  negative   \n",
       "9  254941790757601280  negative   \n",
       "\n",
       "                                               tweet  \n",
       "0  Gas by my house hit $3.39!!!! I'm going to Cha...  \n",
       "3  Iranian general says Israel's Iron Dome can't ...  \n",
       "6  with J Davlar 11th. Main rivals are team Polan...  \n",
       "7  Talking about ACT's &amp;&amp; SAT's, deciding...  \n",
       "9  They may have a SuperBowl in Dallas, but Dalla...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows having 'Not Available'...\n",
    "df = df[df.tweet != 'Not Available']\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A function to convert a tweet into a set of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gas by my house hit $3.39!!!! I'm going to Chapel Hill on Sat. :)\n",
      "['Gas', 'house', 'hit', 'Im', 'going', 'Chapel', 'Hill', 'Sat']\n",
      "Iranian general says Israel's Iron Dome can't deal with their missiles (keep talking like that and we may end up finding out)\n",
      "['Iranian', 'general', 'says', 'Israels', 'Iron', 'Dome', 'cant', 'deal', 'missiles', 'keep', 'talking', 'like', 'may', 'end', 'finding']\n",
      "with J Davlar 11th. Main rivals are team Poland. Hopefully we an make it a successful end to a tough week of training tomorrow.\n",
      "['Davlar', 'Main', 'rivals', 'team', 'Poland', 'Hopefully', 'make', 'successful', 'end', 'tough', 'week', 'training', 'tomorrow']\n",
      "Talking about ACT's &amp;&amp; SAT's, deciding where I want to go to college, applying to colleges and everything about college stresses me out.\n",
      "['Talking', 'ACTs', 'ampamp', 'SATs', 'deciding', 'want', 'go', 'college', 'applying', 'colleges', 'everything', 'college', 'stresses']\n",
      "They may have a SuperBowl in Dallas, but Dallas ain't winning a SuperBowl. Not with that quarterback and owner. @S4NYC @RasmussenPoll\n",
      "['They', 'may', 'SuperBowl', 'Dallas', 'Dallas', 'aint', 'winning', 'SuperBowl', 'Not', 'quarterback', 'owner', 'RasmussenPoll']\n",
      "Im bringing the monster load of candy tomorrow, I just hope it doesn't get all squiched\n",
      "['Im', 'bringing', 'monster', 'load', 'candy', 'tomorrow', 'hope', 'doesnt', 'get', 'squiched']\n",
      "Apple software, retail chiefs out in overhaul: SAN FRANCISCO Apple Inc CEO Tim Cook on Monday replaced the heads... http://t.co/X49ZEOsG\n",
      "['Apple', 'software', 'retail', 'chiefs', 'overhaul', 'SAN', 'FRANCISCO', 'Apple', 'Inc', 'CEO', 'Tim', 'Cook', 'Monday', 'replaced', 'heads']\n",
      "@oluoch @victor_otti @kunjand I just watched it! Sridevi's comeback.... U remember her from the 90s?? Sun mornings on NTA ;)\n",
      "['oluoch', 'victorotti', 'kunjand', 'watched', 'Sridevis', 'comeback', 'remember', 'Sun', 'mornings', 'NTA']\n",
      "#Livewire Nadal confirmed for Mexican Open in February: Rafael Nadal is set to play at the Me... http://t.co/zgUXpcnC #LiveWireAthletics\n",
      "['Livewire', 'Nadal', 'confirmed', 'Mexican', 'Open', 'February', 'Rafael', 'Nadal', 'set', 'play', 'Me', 'LiveWireAthletics']\n",
      "@MsSheLahY I didnt want to just pop up... but yep we have chapel hill next wednesday you should come.. and shes great ill tell her you asked\n",
      "['MsSheLahY', 'didnt', 'want', 'pop', 'yep', 'chapel', 'hill', 'next', 'wednesday', 'come', 'shes', 'great', 'ill', 'tell', 'asked']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "#import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# turn a document into a list of clean tokens\n",
    "def clean_doc(doc):\n",
    "    # Remove links...\n",
    "    doc = re.sub(\"\\w+:\\/\\/\\S+\", \" \", doc)\n",
    "    # split into tokens by white space\n",
    "    tokens = doc.split()\n",
    "    # prepare regex for char filtering\n",
    "    re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    # remove punctuation from each word\n",
    "    tokens = [re_punc.sub('', w) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    return tokens\n",
    "\n",
    "for tweet in df.tweet.head(10):\n",
    "    print(tweet)\n",
    "    print(clean_doc(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process all tweets, and save results in the dataframe..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11918 entries, 0 to 16044\n",
      "Data columns (total 4 columns):\n",
      "id        11918 non-null int64\n",
      "tag       11918 non-null object\n",
      "tweet     11918 non-null object\n",
      "tokens    11918 non-null object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 465.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tag</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>264183816548130816</td>\n",
       "      <td>positive</td>\n",
       "      <td>Gas by my house hit $3.39!!!! I'm going to Cha...</td>\n",
       "      <td>[Gas, house, hit, Im, going, Chapel, Hill, Sat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264249301910310912</td>\n",
       "      <td>negative</td>\n",
       "      <td>Iranian general says Israel's Iron Dome can't ...</td>\n",
       "      <td>[Iranian, general, says, Israels, Iron, Dome, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>264105751826538497</td>\n",
       "      <td>positive</td>\n",
       "      <td>with J Davlar 11th. Main rivals are team Polan...</td>\n",
       "      <td>[Davlar, Main, rivals, team, Poland, Hopefully...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>264094586689953794</td>\n",
       "      <td>negative</td>\n",
       "      <td>Talking about ACT's &amp;amp;&amp;amp; SAT's, deciding...</td>\n",
       "      <td>[Talking, ACTs, ampamp, SATs, deciding, want, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>254941790757601280</td>\n",
       "      <td>negative</td>\n",
       "      <td>They may have a SuperBowl in Dallas, but Dalla...</td>\n",
       "      <td>[They, may, SuperBowl, Dallas, Dallas, aint, w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id       tag  \\\n",
       "0  264183816548130816  positive   \n",
       "3  264249301910310912  negative   \n",
       "6  264105751826538497  positive   \n",
       "7  264094586689953794  negative   \n",
       "9  254941790757601280  negative   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  Gas by my house hit $3.39!!!! I'm going to Cha...   \n",
       "3  Iranian general says Israel's Iron Dome can't ...   \n",
       "6  with J Davlar 11th. Main rivals are team Polan...   \n",
       "7  Talking about ACT's &amp;&amp; SAT's, deciding...   \n",
       "9  They may have a SuperBowl in Dallas, but Dalla...   \n",
       "\n",
       "                                              tokens  \n",
       "0    [Gas, house, hit, Im, going, Chapel, Hill, Sat]  \n",
       "3  [Iranian, general, says, Israels, Iron, Dome, ...  \n",
       "6  [Davlar, Main, rivals, team, Poland, Hopefully...  \n",
       "7  [Talking, ACTs, ampamp, SATs, deciding, want, ...  \n",
       "9  [They, may, SuperBowl, Dallas, Dallas, aint, w...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df['tokens'] = np.array([ clean_doc(tweet) for tweet in df.tweet ])\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform all actions also for dev/test data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpattern = '../Exercise_2-TwitterSentimentAnalysis/data/twitter-20*dev-*.tsv'\n",
    "devfs    = [filename for filename in sorted(glob.glob(fpattern))]\n",
    "fpattern = '../Exercise_2-TwitterSentimentAnalysis/data/twitter-20*test-*.tsv'\n",
    "testfs   = [filename for filename in sorted(glob.glob(fpattern))]\n",
    "df_dev   = pd.concat([pd.read_csv(f, sep=\"\\t\", names=column_names) for f in devfs],  ignore_index=True, sort=True)\n",
    "df_test  = pd.concat([pd.read_csv(f, sep=\"\\t\", names=column_names) for f in testfs], ignore_index=True, sort=True)\n",
    "df_dev   = df_dev[df_dev.tweet != 'Not Available']\n",
    "df_test  = df_test[df_test.tweet != 'Not Available']\n",
    "df_dev['tokens']  = np.array([ clean_doc(tweet) for tweet in df_dev.tweet ])\n",
    "df_test['tokens'] = np.array([ clean_doc(tweet) for tweet in df_test.tweet ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract our vocabulary..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets:  30438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('may', 4005),\n",
       " ('tomorrow', 3911),\n",
       " ('The', 1926),\n",
       " ('Im', 1750),\n",
       " ('going', 1698),\n",
       " ('amp', 1679),\n",
       " ('day', 1659),\n",
       " ('see', 1657),\n",
       " ('Friday', 1640),\n",
       " ('Sunday', 1572)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "vocabulary = Counter()\n",
    "for tweet_tokens in itertools.chain(df.tokens, df_dev.tokens, df_test.tokens):\n",
    "    vocabulary.update(tweet_tokens)\n",
    "\n",
    "print('Total tweets: ', sum(1 for _ in itertools.chain(df.tokens, df_dev.tokens, df_test.tokens)))\n",
    "vocabulary.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter words using the vocabulary..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gas by my house hit $3.39!!!! I'm going to Chapel Hill on Sat. :)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Gas house hit Im going Chapel Hill Sat'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def token_to_vector_words(tokens, vocabulary):\n",
    "    tokens = [w for w in tokens if w in vocabulary]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "print(df.tweet[0])\n",
    "token_to_vector_words(df.tokens[0], vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11918 entries, 0 to 16044\n",
      "Data columns (total 5 columns):\n",
      "id               11918 non-null int64\n",
      "tag              11918 non-null object\n",
      "tweet            11918 non-null object\n",
      "tokens           11918 non-null object\n",
      "vector_tokens    11918 non-null object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 878.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tag</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tokens</th>\n",
       "      <th>vector_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>264183816548130816</td>\n",
       "      <td>positive</td>\n",
       "      <td>Gas by my house hit $3.39!!!! I'm going to Cha...</td>\n",
       "      <td>[Gas, house, hit, Im, going, Chapel, Hill, Sat]</td>\n",
       "      <td>Gas house hit Im going Chapel Hill Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264249301910310912</td>\n",
       "      <td>negative</td>\n",
       "      <td>Iranian general says Israel's Iron Dome can't ...</td>\n",
       "      <td>[Iranian, general, says, Israels, Iron, Dome, ...</td>\n",
       "      <td>Iranian general says Israels Iron Dome cant de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>264105751826538497</td>\n",
       "      <td>positive</td>\n",
       "      <td>with J Davlar 11th. Main rivals are team Polan...</td>\n",
       "      <td>[Davlar, Main, rivals, team, Poland, Hopefully...</td>\n",
       "      <td>Davlar Main rivals team Poland Hopefully make ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>264094586689953794</td>\n",
       "      <td>negative</td>\n",
       "      <td>Talking about ACT's &amp;amp;&amp;amp; SAT's, deciding...</td>\n",
       "      <td>[Talking, ACTs, ampamp, SATs, deciding, want, ...</td>\n",
       "      <td>Talking ACTs ampamp SATs deciding want go coll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>254941790757601280</td>\n",
       "      <td>negative</td>\n",
       "      <td>They may have a SuperBowl in Dallas, but Dalla...</td>\n",
       "      <td>[They, may, SuperBowl, Dallas, Dallas, aint, w...</td>\n",
       "      <td>They may SuperBowl Dallas Dallas aint winning ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id       tag  \\\n",
       "0  264183816548130816  positive   \n",
       "3  264249301910310912  negative   \n",
       "6  264105751826538497  positive   \n",
       "7  264094586689953794  negative   \n",
       "9  254941790757601280  negative   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  Gas by my house hit $3.39!!!! I'm going to Cha...   \n",
       "3  Iranian general says Israel's Iron Dome can't ...   \n",
       "6  with J Davlar 11th. Main rivals are team Polan...   \n",
       "7  Talking about ACT's &amp;&amp; SAT's, deciding...   \n",
       "9  They may have a SuperBowl in Dallas, but Dalla...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0    [Gas, house, hit, Im, going, Chapel, Hill, Sat]   \n",
       "3  [Iranian, general, says, Israels, Iron, Dome, ...   \n",
       "6  [Davlar, Main, rivals, team, Poland, Hopefully...   \n",
       "7  [Talking, ACTs, ampamp, SATs, deciding, want, ...   \n",
       "9  [They, may, SuperBowl, Dallas, Dallas, aint, w...   \n",
       "\n",
       "                                       vector_tokens  \n",
       "0             Gas house hit Im going Chapel Hill Sat  \n",
       "3  Iranian general says Israels Iron Dome cant de...  \n",
       "6  Davlar Main rivals team Poland Hopefully make ...  \n",
       "7  Talking ACTs ampamp SATs deciding want go coll...  \n",
       "9  They may SuperBowl Dallas Dallas aint winning ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vector_tokens']      = np.array([ token_to_vector_words(tweet, vocabulary) for tweet in df.tokens ])\n",
    "df_dev['vector_tokens']  = np.array([ token_to_vector_words(tweet, vocabulary) for tweet in df_dev.tokens ])\n",
    "df_test['vector_tokens'] = np.array([ token_to_vector_words(tweet, vocabulary) for tweet in df_test.tokens ])\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tag</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tokens</th>\n",
       "      <th>vector_tokens</th>\n",
       "      <th>btag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>638060586258038784</td>\n",
       "      <td>neutral</td>\n",
       "      <td>05 Beat it - Michael Jackson - Thriller (25th ...</td>\n",
       "      <td>[Beat, Michael, Jackson, Thriller, Anniversary...</td>\n",
       "      <td>Beat Michael Jackson Thriller Anniversary Edit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>638061181823922176</td>\n",
       "      <td>positive</td>\n",
       "      <td>Jay Z joins Instagram with nostalgic tribute t...</td>\n",
       "      <td>[Jay, joins, Instagram, nostalgic, tribute, Mi...</td>\n",
       "      <td>Jay joins Instagram nostalgic tribute Michael ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>638083821364244480</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Michael Jackson: Bad 25th Anniversary Edition ...</td>\n",
       "      <td>[Michael, Jackson, Bad, Anniversary, Edition, ...</td>\n",
       "      <td>Michael Jackson Bad Anniversary Edition Pictur...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>638125563790557184</td>\n",
       "      <td>positive</td>\n",
       "      <td>18th anniv of Princess Diana's death. I still ...</td>\n",
       "      <td>[anniv, Princess, Dianas, death, still, want, ...</td>\n",
       "      <td>anniv Princess Dianas death still want believe...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>638130776727535617</td>\n",
       "      <td>positive</td>\n",
       "      <td>@oridaganjazz The 1st time I heard Michael Jac...</td>\n",
       "      <td>[oridaganjazz, The, time, heard, Michael, Jack...</td>\n",
       "      <td>oridaganjazz The time heard Michael Jackson si...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>638162155250954241</td>\n",
       "      <td>negative</td>\n",
       "      <td>@etbowser do u enjoy his 2nd rate Michael Jack...</td>\n",
       "      <td>[etbowser, enjoy, rate, Michael, Jackson, bit,...</td>\n",
       "      <td>etbowser enjoy rate Michael Jackson bit Honest...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id       tag  \\\n",
       "0  638060586258038784   neutral   \n",
       "1  638061181823922176  positive   \n",
       "2  638083821364244480   neutral   \n",
       "4  638125563790557184  positive   \n",
       "5  638130776727535617  positive   \n",
       "8  638162155250954241  negative   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  05 Beat it - Michael Jackson - Thriller (25th ...   \n",
       "1  Jay Z joins Instagram with nostalgic tribute t...   \n",
       "2  Michael Jackson: Bad 25th Anniversary Edition ...   \n",
       "4  18th anniv of Princess Diana's death. I still ...   \n",
       "5  @oridaganjazz The 1st time I heard Michael Jac...   \n",
       "8  @etbowser do u enjoy his 2nd rate Michael Jack...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Beat, Michael, Jackson, Thriller, Anniversary...   \n",
       "1  [Jay, joins, Instagram, nostalgic, tribute, Mi...   \n",
       "2  [Michael, Jackson, Bad, Anniversary, Edition, ...   \n",
       "4  [anniv, Princess, Dianas, death, still, want, ...   \n",
       "5  [oridaganjazz, The, time, heard, Michael, Jack...   \n",
       "8  [etbowser, enjoy, rate, Michael, Jackson, bit,...   \n",
       "\n",
       "                                       vector_tokens  btag  \n",
       "0  Beat Michael Jackson Thriller Anniversary Edit...     1  \n",
       "1  Jay joins Instagram nostalgic tribute Michael ...     2  \n",
       "2  Michael Jackson Bad Anniversary Edition Pictur...     1  \n",
       "4  anniv Princess Dianas death still want believe...     2  \n",
       "5  oridaganjazz The time heard Michael Jackson si...     2  \n",
       "8  etbowser enjoy rate Michael Jackson bit Honest...     0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map tag from class (positive, negative) to numbers...\n",
    "df['btag']      = df.tag.astype('category').cat.codes\n",
    "df_dev['btag']  = df_dev.tag.astype('category').cat.codes\n",
    "df_test['btag'] = df_test.tag.astype('category').cat.codes\n",
    "df_dev.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets make our vectors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11918, 23741) (16999, 23741) (11918,) (16999,)\n",
      "(11918, 3)\n",
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df.vector_tokens)\n",
    "#print(tokenizer.word_counts)\n",
    "#print(tokenizer.document_count)\n",
    "#print(tokenizer.word_index)\n",
    "#print(tokenizer.word_docs)\n",
    "Xtrain = tokenizer.texts_to_matrix(df.vector_tokens, mode='freq')\n",
    "Ytrain = df.btag\n",
    "Xtest  = tokenizer.texts_to_matrix(df_test.vector_tokens, mode='freq')\n",
    "Ytest  = df_test.btag\n",
    "print(Xtrain.shape, Xtest.shape, Ytrain.shape, Ytest.shape)\n",
    "#print(Ytrain[0])\n",
    "#print(*Xtrain[0], sep = \"\\n\")\n",
    "from keras.utils import np_utils\n",
    "Ytrain_one_hot = np_utils.to_categorical(Ytrain)\n",
    "Ytest_one_hot  = np_utils.to_categorical(Ytest)\n",
    "print(Ytrain_one_hot.shape)\n",
    "print(Ytrain_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple MLP model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23741\n"
     ]
    }
   ],
   "source": [
    "n_words = Xtest.shape[1]\n",
    "print(n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                1519488   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 1,519,683\n",
      "Trainable params: 1,519,683\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"191pt\" viewBox=\"0.00 0.00 169.00 191.00\" width=\"169pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 187)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-187 165,-187 165,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140629138672440 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140629138672440</title>\n",
       "<polygon fill=\"none\" points=\"0,-146.5 0,-182.5 161,-182.5 161,-146.5 0,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-160.8\">dense_1_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140629144643792 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140629144643792</title>\n",
       "<polygon fill=\"none\" points=\"29.5,-73.5 29.5,-109.5 131.5,-109.5 131.5,-73.5 29.5,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-87.8\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 140629138672440&#45;&gt;140629144643792 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140629138672440-&gt;140629144643792</title>\n",
       "<path d=\"M80.5,-146.4551C80.5,-138.3828 80.5,-128.6764 80.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"84.0001,-119.5903 80.5,-109.5904 77.0001,-119.5904 84.0001,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140629144644016 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140629144644016</title>\n",
       "<polygon fill=\"none\" points=\"29.5,-.5 29.5,-36.5 131.5,-36.5 131.5,-.5 29.5,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-14.8\">dense_2: Dense</text>\n",
       "</g>\n",
       "<!-- 140629144643792&#45;&gt;140629144644016 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140629144643792-&gt;140629144644016</title>\n",
       "<path d=\"M80.5,-73.4551C80.5,-65.3828 80.5,-55.6764 80.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"84.0001,-46.5903 80.5,-36.5904 77.0001,-46.5904 84.0001,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "# define network\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='relu', input_shape=(n_words,)))\n",
    "model.add(Dense(units=3, activation='softmax'))\n",
    "# compile network\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])\n",
    "# summarize defined model\n",
    "model.summary()\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit our network..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " - 10s - loss: 0.2109 - acc: 0.4274\n",
      "Epoch 2/30\n",
      " - 7s - loss: 0.2047 - acc: 0.4304\n",
      "Epoch 3/30\n",
      " - 7s - loss: 0.2037 - acc: 0.4359\n",
      "Epoch 4/30\n",
      " - 7s - loss: 0.2034 - acc: 0.4404\n",
      "Epoch 5/30\n",
      " - 7s - loss: 0.2033 - acc: 0.4405\n",
      "Epoch 6/30\n",
      " - 7s - loss: 0.2033 - acc: 0.4502\n",
      "Epoch 7/30\n",
      " - 7s - loss: 0.2032 - acc: 0.4496\n",
      "Epoch 8/30\n",
      " - 7s - loss: 0.2032 - acc: 0.4481\n",
      "Epoch 9/30\n",
      " - 7s - loss: 0.2031 - acc: 0.4679\n",
      "Epoch 10/30\n",
      " - 7s - loss: 0.2031 - acc: 0.4567\n",
      "Epoch 11/30\n",
      " - 8s - loss: 0.2031 - acc: 0.4690\n",
      "Epoch 12/30\n",
      " - 9s - loss: 0.2030 - acc: 0.4660\n",
      "Epoch 13/30\n",
      " - 9s - loss: 0.2030 - acc: 0.4737\n",
      "Epoch 14/30\n",
      " - 9s - loss: 0.2029 - acc: 0.4800\n",
      "Epoch 15/30\n",
      " - 7s - loss: 0.2029 - acc: 0.4940\n",
      "Epoch 16/30\n",
      " - 7s - loss: 0.2028 - acc: 0.5019\n",
      "Epoch 17/30\n",
      " - 7s - loss: 0.2028 - acc: 0.5047\n",
      "Epoch 18/30\n",
      " - 7s - loss: 0.2028 - acc: 0.4961\n",
      "Epoch 19/30\n",
      " - 8s - loss: 0.2027 - acc: 0.5171\n",
      "Epoch 20/30\n",
      " - 7s - loss: 0.2027 - acc: 0.4938\n",
      "Epoch 21/30\n",
      " - 7s - loss: 0.2026 - acc: 0.4909\n",
      "Epoch 22/30\n",
      " - 7s - loss: 0.2026 - acc: 0.5210\n",
      "Epoch 23/30\n",
      " - 7s - loss: 0.2025 - acc: 0.5117\n",
      "Epoch 24/30\n",
      " - 7s - loss: 0.2025 - acc: 0.5153\n",
      "Epoch 25/30\n",
      " - 7s - loss: 0.2024 - acc: 0.5187\n",
      "Epoch 26/30\n",
      " - 7s - loss: 0.2024 - acc: 0.5291\n",
      "Epoch 27/30\n",
      " - 7s - loss: 0.2023 - acc: 0.5258\n",
      "Epoch 28/30\n",
      " - 7s - loss: 0.2023 - acc: 0.5011\n",
      "Epoch 29/30\n",
      " - 7s - loss: 0.2022 - acc: 0.5138\n",
      "Epoch 30/30\n",
      " - 7s - loss: 0.2021 - acc: 0.5008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe6c7bec9b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit network\n",
    "model.fit(Xtrain, Ytrain_one_hot, batch_size=10, epochs=30, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate our fit network...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 36.978646\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "loss, acc = model.evaluate(Xtest, Ytest_one_hot, verbose=2)\n",
    "print('Test Accuracy: %f' % (acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Word Scoring Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def prepare_data(train_df, test_df, mode):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(train_df.vector_tokens)\n",
    "    Xtrain = tokenizer.texts_to_matrix(train_df.vector_tokens, mode=mode)\n",
    "    Ytrain = np_utils.to_categorical(train_df.btag)\n",
    "    Xtest  = tokenizer.texts_to_matrix(test_df.vector_tokens, mode=mode)\n",
    "    Ytest  = np_utils.to_categorical(test_df.btag)\n",
    "    return Xtrain, Ytrain, Xtest, Ytest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate a neural network model\n",
    "def evaluate_mode(Xtrain, Ytrain, Xtest, Ytest, mode):\n",
    "    scores = list()\n",
    "    n_repeats = 3\n",
    "    n_words = Xtest.shape[1]\n",
    "    for i in range(n_repeats):\n",
    "        # define network\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=64, input_shape=(n_words,), activation='relu'))\n",
    "        model.add(Dense(units=3, activation='softmax'))\n",
    "        # compile network\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        # fit network\n",
    "        model.fit(Xtrain, Ytrain, epochs=10, verbose=2)\n",
    "        # evaluate\n",
    "        loss, acc = model.evaluate(Xtest, Ytest, verbose=0)\n",
    "        scores.append(acc)\n",
    "        print('%s %d accuracy: %s' % (mode, (i+1), acc))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 6s - loss: 0.5135 - acc: 0.7401\n",
      "Epoch 2/10\n",
      " - 5s - loss: 0.2917 - acc: 0.8797\n",
      "Epoch 3/10\n",
      " - 8s - loss: 0.1365 - acc: 0.9539\n",
      "Epoch 4/10\n",
      " - 10s - loss: 0.0673 - acc: 0.9809\n",
      "Epoch 5/10\n",
      " - 11s - loss: 0.0366 - acc: 0.9909\n",
      "Epoch 6/10\n",
      " - 11s - loss: 0.0232 - acc: 0.9945\n",
      "Epoch 7/10\n",
      " - 12s - loss: 0.0151 - acc: 0.9969\n",
      "Epoch 8/10\n",
      " - 11s - loss: 0.0121 - acc: 0.9972\n",
      "Epoch 9/10\n",
      " - 11s - loss: 0.0097 - acc: 0.9981\n",
      "Epoch 10/10\n",
      " - 11s - loss: 0.0080 - acc: 0.9980\n",
      "binary 1 accuracy: 0.694884013239724\n",
      "Epoch 1/10\n",
      " - 6s - loss: 0.5267 - acc: 0.7321\n",
      "Epoch 2/10\n",
      " - 6s - loss: 0.3055 - acc: 0.8708\n",
      "Epoch 3/10\n",
      " - 8s - loss: 0.1448 - acc: 0.9498\n",
      "Epoch 4/10\n",
      " - 10s - loss: 0.0716 - acc: 0.9788\n",
      "Epoch 5/10\n",
      " - 11s - loss: 0.0384 - acc: 0.9907\n",
      "Epoch 6/10\n",
      " - 12s - loss: 0.0237 - acc: 0.9947\n",
      "Epoch 7/10\n",
      " - 11s - loss: 0.0159 - acc: 0.9966\n",
      "Epoch 8/10\n",
      " - 11s - loss: 0.0112 - acc: 0.9973\n",
      "Epoch 9/10\n",
      " - 11s - loss: 0.0093 - acc: 0.9977\n",
      "Epoch 10/10\n",
      " - 11s - loss: 0.0074 - acc: 0.9983\n",
      "binary 2 accuracy: 0.6950604927891163\n",
      "Epoch 1/10\n",
      " - 6s - loss: 0.5158 - acc: 0.7397\n",
      "Epoch 2/10\n",
      " - 6s - loss: 0.2938 - acc: 0.8765\n",
      "Epoch 3/10\n",
      " - 8s - loss: 0.1373 - acc: 0.9525\n",
      "Epoch 4/10\n",
      " - 10s - loss: 0.0643 - acc: 0.9826\n",
      "Epoch 5/10\n",
      " - 11s - loss: 0.0353 - acc: 0.9907\n",
      "Epoch 6/10\n",
      " - 11s - loss: 0.0218 - acc: 0.9951\n",
      "Epoch 7/10\n",
      " - 11s - loss: 0.0148 - acc: 0.9968\n",
      "Epoch 8/10\n",
      " - 11s - loss: 0.0118 - acc: 0.9975\n",
      "Epoch 9/10\n",
      " - 11s - loss: 0.0095 - acc: 0.9977\n",
      "Epoch 10/10\n",
      " - 11s - loss: 0.0067 - acc: 0.9985\n",
      "binary 3 accuracy: 0.6918446172145586\n",
      "Epoch 1/10\n",
      " - 6s - loss: 0.5190 - acc: 0.7371\n",
      "Epoch 2/10\n",
      " - 6s - loss: 0.2938 - acc: 0.8802\n",
      "Epoch 3/10\n",
      " - 8s - loss: 0.1403 - acc: 0.9518\n",
      "Epoch 4/10\n",
      " - 10s - loss: 0.0699 - acc: 0.9801\n",
      "Epoch 5/10\n",
      " - 10s - loss: 0.0400 - acc: 0.9898\n",
      "Epoch 6/10\n",
      " - 11s - loss: 0.0245 - acc: 0.9943\n",
      "Epoch 7/10\n",
      " - 11s - loss: 0.0164 - acc: 0.9966\n",
      "Epoch 8/10\n",
      " - 11s - loss: 0.0134 - acc: 0.9969\n",
      "Epoch 9/10\n",
      " - 10s - loss: 0.0106 - acc: 0.9980\n",
      "Epoch 10/10\n",
      " - 10s - loss: 0.0083 - acc: 0.9983\n",
      "count 1 accuracy: 0.6942761359379441\n",
      "Epoch 1/10\n",
      " - 5s - loss: 0.5205 - acc: 0.7363\n",
      "Epoch 2/10\n",
      " - 6s - loss: 0.2974 - acc: 0.8792\n",
      "Epoch 3/10\n",
      " - 8s - loss: 0.1413 - acc: 0.9526\n",
      "Epoch 4/10\n",
      " - 11s - loss: 0.0685 - acc: 0.9797\n",
      "Epoch 5/10\n",
      " - 11s - loss: 0.0379 - acc: 0.9913\n",
      "Epoch 6/10\n",
      " - 11s - loss: 0.0245 - acc: 0.9944\n",
      "Epoch 7/10\n",
      " - 11s - loss: 0.0163 - acc: 0.9965\n",
      "Epoch 8/10\n",
      " - 11s - loss: 0.0128 - acc: 0.9972\n",
      "Epoch 9/10\n",
      " - 11s - loss: 0.0109 - acc: 0.9975\n",
      "Epoch 10/10\n",
      " - 11s - loss: 0.0084 - acc: 0.9982\n",
      "count 2 accuracy: 0.6949428406257658\n",
      "Epoch 1/10\n",
      " - 6s - loss: 0.5181 - acc: 0.7370\n",
      "Epoch 2/10\n",
      " - 6s - loss: 0.2915 - acc: 0.8796\n",
      "Epoch 3/10\n",
      " - 8s - loss: 0.1367 - acc: 0.9538\n",
      "Epoch 4/10\n",
      " - 10s - loss: 0.0661 - acc: 0.9816\n",
      "Epoch 5/10\n",
      " - 11s - loss: 0.0372 - acc: 0.9915\n",
      "Epoch 6/10\n",
      " - 12s - loss: 0.0235 - acc: 0.9947\n",
      "Epoch 7/10\n",
      " - 11s - loss: 0.0171 - acc: 0.9964\n",
      "Epoch 8/10\n",
      " - 10s - loss: 0.0123 - acc: 0.9975\n",
      "Epoch 9/10\n",
      " - 10s - loss: 0.0105 - acc: 0.9977\n",
      "Epoch 10/10\n",
      " - 10s - loss: 0.0089 - acc: 0.9980\n",
      "count 3 accuracy: 0.6919622730455635\n",
      "Epoch 1/10\n",
      " - 6s - loss: 0.5110 - acc: 0.7422\n",
      "Epoch 2/10\n",
      " - 6s - loss: 0.1747 - acc: 0.9360\n",
      "Epoch 3/10\n",
      " - 10s - loss: 0.0524 - acc: 0.9852\n",
      "Epoch 4/10\n",
      " - 12s - loss: 0.0218 - acc: 0.9943\n",
      "Epoch 5/10\n",
      " - 13s - loss: 0.0139 - acc: 0.9963\n",
      "Epoch 6/10\n",
      " - 13s - loss: 0.0090 - acc: 0.9974\n",
      "Epoch 7/10\n",
      " - 13s - loss: 0.0070 - acc: 0.9978\n",
      "Epoch 8/10\n",
      " - 13s - loss: 0.0063 - acc: 0.9982\n",
      "Epoch 9/10\n",
      " - 13s - loss: 0.0045 - acc: 0.9983\n",
      "Epoch 10/10\n",
      " - 13s - loss: 0.0043 - acc: 0.9984\n",
      "tfidf 1 accuracy: 0.6897660655564116\n",
      "Epoch 1/10\n",
      " - 5s - loss: 0.5112 - acc: 0.7420\n",
      "Epoch 2/10\n",
      " - 5s - loss: 0.1784 - acc: 0.9350\n",
      "Epoch 3/10\n",
      " - 9s - loss: 0.0548 - acc: 0.9835\n",
      "Epoch 4/10\n",
      " - 12s - loss: 0.0226 - acc: 0.9940\n",
      "Epoch 5/10\n",
      " - 13s - loss: 0.0131 - acc: 0.9964\n",
      "Epoch 6/10\n",
      " - 13s - loss: 0.0100 - acc: 0.9973\n",
      "Epoch 7/10\n",
      " - 13s - loss: 0.0064 - acc: 0.9979\n",
      "Epoch 8/10\n",
      " - 14s - loss: 0.0066 - acc: 0.9983\n",
      "Epoch 9/10\n",
      " - 16s - loss: 0.0054 - acc: 0.9983\n",
      "Epoch 10/10\n",
      " - 17s - loss: 0.0050 - acc: 0.9984\n",
      "tfidf 2 accuracy: 0.6917269641535795\n",
      "Epoch 1/10\n",
      " - 9s - loss: 0.5126 - acc: 0.7424\n",
      "Epoch 2/10\n",
      " - 8s - loss: 0.1735 - acc: 0.9361\n",
      "Epoch 3/10\n",
      " - 12s - loss: 0.0517 - acc: 0.9857\n",
      "Epoch 4/10\n",
      " - 15s - loss: 0.0220 - acc: 0.9937\n",
      "Epoch 5/10\n",
      " - 13s - loss: 0.0116 - acc: 0.9964\n",
      "Epoch 6/10\n",
      " - 13s - loss: 0.0074 - acc: 0.9974\n",
      "Epoch 7/10\n",
      " - 15s - loss: 0.0058 - acc: 0.9978\n",
      "Epoch 8/10\n",
      " - 17s - loss: 0.0051 - acc: 0.9982\n",
      "Epoch 9/10\n",
      " - 17s - loss: 0.0036 - acc: 0.9985\n",
      "Epoch 10/10\n",
      " - 17s - loss: 0.0035 - acc: 0.9986\n",
      "tfidf 3 accuracy: 0.6942369162394683\n",
      "Epoch 1/10\n",
      " - 8s - loss: 0.5760 - acc: 0.6855\n",
      "Epoch 2/10\n",
      " - 8s - loss: 0.4789 - acc: 0.7921\n",
      "Epoch 3/10\n",
      " - 9s - loss: 0.3743 - acc: 0.8459\n",
      "Epoch 4/10\n",
      " - 9s - loss: 0.2845 - acc: 0.8939\n",
      "Epoch 5/10\n",
      " - 9s - loss: 0.2152 - acc: 0.9298\n",
      "Epoch 6/10\n",
      " - 9s - loss: 0.1627 - acc: 0.9527\n",
      "Epoch 7/10\n",
      " - 9s - loss: 0.1244 - acc: 0.9670\n",
      "Epoch 8/10\n",
      " - 10s - loss: 0.0960 - acc: 0.9778\n",
      "Epoch 9/10\n",
      " - 10s - loss: 0.0740 - acc: 0.9847\n",
      "Epoch 10/10\n",
      " - 10s - loss: 0.0575 - acc: 0.9891\n",
      "freq 1 accuracy: 0.6935702101876717\n",
      "Epoch 1/10\n",
      " - 8s - loss: 0.5759 - acc: 0.6869\n",
      "Epoch 2/10\n",
      " - 8s - loss: 0.4726 - acc: 0.7994\n",
      "Epoch 3/10\n",
      " - 9s - loss: 0.3689 - acc: 0.8476\n",
      "Epoch 4/10\n",
      " - 10s - loss: 0.2811 - acc: 0.8948\n",
      "Epoch 5/10\n",
      " - 9s - loss: 0.2112 - acc: 0.9314\n",
      "Epoch 6/10\n",
      " - 9s - loss: 0.1583 - acc: 0.9547\n",
      "Epoch 7/10\n",
      " - 10s - loss: 0.1208 - acc: 0.9688\n",
      "Epoch 8/10\n",
      " - 8s - loss: 0.0933 - acc: 0.9787\n",
      "Epoch 9/10\n",
      " - 9s - loss: 0.0727 - acc: 0.9850\n",
      "Epoch 10/10\n",
      " - 10s - loss: 0.0573 - acc: 0.9884\n",
      "freq 2 accuracy: 0.6942369154926131\n",
      "Epoch 1/10\n",
      " - 8s - loss: 0.5788 - acc: 0.6824\n",
      "Epoch 2/10\n",
      " - 9s - loss: 0.4869 - acc: 0.7913\n",
      "Epoch 3/10\n",
      " - 8s - loss: 0.3824 - acc: 0.8456\n",
      "Epoch 4/10\n",
      " - 8s - loss: 0.2928 - acc: 0.8908\n",
      "Epoch 5/10\n",
      " - 8s - loss: 0.2221 - acc: 0.9257\n",
      "Epoch 6/10\n",
      " - 9s - loss: 0.1694 - acc: 0.9503\n",
      "Epoch 7/10\n",
      " - 9s - loss: 0.1295 - acc: 0.9654\n",
      "Epoch 8/10\n",
      " - 9s - loss: 0.1002 - acc: 0.9759\n",
      "Epoch 9/10\n",
      " - 9s - loss: 0.0779 - acc: 0.9836\n",
      "Epoch 10/10\n",
      " - 8s - loss: 0.0613 - acc: 0.9888\n",
      "freq 3 accuracy: 0.696942959156336\n"
     ]
    }
   ],
   "source": [
    "# run experiment\n",
    "modes = ['binary', 'count', 'tfidf', 'freq']\n",
    "results = pd.DataFrame()\n",
    "for mode in modes:\n",
    "    # prepare data for mode\n",
    "    Xtrain, Ytrain, Xtest, Ytest = prepare_data(df, df_test, mode)\n",
    "    # evaluate model on data for mode\n",
    "    results[mode] = evaluate_mode(Xtrain, Ytrain, Xtest, Ytest, mode)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         binary     count     tfidf      freq\n",
      "count  3.000000  3.000000  3.000000  3.000000\n",
      "mean   0.693930  0.693727  0.691910  0.694917\n",
      "std    0.001808  0.001564  0.002241  0.001786\n",
      "min    0.691845  0.691962  0.689766  0.693570\n",
      "25%    0.693364  0.693119  0.690747  0.693904\n",
      "50%    0.694884  0.694276  0.691727  0.694237\n",
      "75%    0.694972  0.694609  0.692982  0.695590\n",
      "max    0.695060  0.694943  0.694237  0.696943\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "# summarise results\n",
    "print(results.describe())\n",
    "# plot results\n",
    "results.boxplot()\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
